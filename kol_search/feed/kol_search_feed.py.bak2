#encoding:utf-8
import datetime
import time
from pymur import QueryEnvironment
from math import exp
import jieba
import json

from information_retrieval import get_query_results
from make_query_string import make_query_string
#filreq(#syn( 3.category 4.category 5.category 10.category 11.category ) #weight(1.0 #prior(QualityRank) 0.5 #combine(#wsum( 2.0 #3(福特 林肯 MKC).(keywords)  0.5 #3(福特 林肯 MKC).nz_cx 0.1 #3(福特 林肯 MKC)) #wsum( 2.0 #any:nz_sx_price.(keywords)  0.5 #any:nz_sx_price 0.1 价格))))
import sys
reload(sys)
sys.setdefaultencoding('utf-8')

def process_relevance(relevance):
    return min(int(exp(relevance)*1000000),1000000)
    
class FeedData():
    
    def __init__(self,keyword,site=0,flag=''):
        self.keyword = keyword
        self.site = site
        self.feed_log = open('feed.log','a+')
        
    #根据query_string查询结果
    def fetch_query_results(self,query_string,num=200):
        index_path = '/disk1/kol_search_index/index'
        query_index = QueryEnvironment()
        query_index.addIndex(index_path)
        #根据query_string查询结果
        print query_string
        docs = query_index.runQuery(query_string,num)
        #解析查询的结果
        results = get_query_results(query_index,docs)
        datas = {}
        flag = 0
        for result in results:
#             userid = result['userid']
#             site = result['site']
            result['relevance'] = process_relevance(result['relevance'])
            datas.update({flag:result})
            flag += 1
        query_index.close()
        return datas
    
    def process(self):
        self.feed_log.write('='*20+'start feed'+'='*20+'\n')
        query_string = make_query_string(self.keyword,self.site)
        #query_string = '#filreq( #band(#equals(site 1) 冷兔) #weight(5.0 冷兔.(DOCNO) 5.0 冷兔.(author) 2.0 冷兔.(abs) 2.0 冷兔.(authenticate) 1.0 冷兔.(hot)))'
        results = self.fetch_query_results(query_string)
        self.feed_log.write('='*20+'end feed'+'='*20+'\n')
        #print results
        return json.dumps(results)

if __name__ == '__main__':
    #curdate格式必须为2015-03-27
#     if len(sys.argv)==2:
#         #get curdate
#         #python feed.py curdate
#         keyword = sys.argv[1]
#         feed = FeedData(keyword)
#         datas = feed.process()
#         print datas
#     else:
#         raise 'need one keyword'
        import time
#         keywords = ['老王','老王','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','卡娃微卡','卡娃微卡','卡娃微卡','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','王兮兮Shirley','卡娃微卡','卡娃微卡','卡娃微卡']
        keywords = ['冷兔']
        flag = 0
        for keyword in keywords:
            site = '0'
            feed = FeedData(keyword,site=0)
            time.sleep(0.1)
            datas = feed.process()
            print datas
        
        

